{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# canonical import statements\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# images (for the discriminator)\n",
    "X = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "# noise vector (for the generator)\n",
    "Z = tf.placeholder(tf.float32, shape=[None, 100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def xavier(shape):\n",
    "    return tf.truncated_normal(shape = shape, stddev = 1.0/tf.sqrt(shape[0]/2.0)) #\"xavier\" initialization of weights\n",
    "\n",
    "class discriminator_network:\n",
    "    \"\"\"MNIST IMAGE(s): x * 784 -> 128 hidden units -> 1 output neuron (probability of being real)\"\"\"\n",
    "    def __init__(self):\n",
    "        self.d_w1 = tf.Variable(xavier([784,128]))\n",
    "        self.d_b1 = tf.Variable(tf.zeros(shape=[128]))\n",
    "        self.d_w2 = tf.Variable(xavier([128,1]))\n",
    "        self.d_b2 = tf.Variable(tf.zeros(shape=[1]))\n",
    "    \n",
    "    def discriminator(self, x):\n",
    "        d_hfc_1 = tf.nn.relu(tf.matmul(x, self.d_w1) + self.d_b1)\n",
    "        d_logit = tf.matmul(d_hfc_1, self.d_w2) + self.d_b2\n",
    "        d_prob = tf.nn.sigmoid(d_logit)\n",
    "        return d_prob, d_logit\n",
    "    \n",
    "    def get_trainable_vars(self):\n",
    "        return [self.d_w1, self.d_b1, self.d_w2, self.d_b2]\n",
    "\n",
    "class generator_network:\n",
    "    \"\"\"Random noise vector (100 dim assumed) -> expand to 128 units -> output 784 units (MNIST dim)\"\"\"\n",
    "    def __init__(self):\n",
    "        self.g_w1 = tf.Variable(xavier([100, 128])) # 100d noise vector assumed. Output 128 hidden units in first layer\n",
    "        self.g_b1 = tf.Variable(tf.zeros(shape=[128]))\n",
    "        self.g_w2 = tf.Variable(xavier([128, 784])) # 784 outputs\n",
    "        self.g_b2 = tf.Variable(tf.zeros(shape=[784]))\n",
    "    \n",
    "    def generator(self, z):\n",
    "        g_hfc_1 = tf.nn.relu(tf.matmul(z, self.g_w1) + self.g_b1)\n",
    "        return tf.nn.sigmoid(tf.matmul(g_hfc_1, self.g_w2) + self.g_b2)\n",
    "    \n",
    "    def get_trainable_vars(self):\n",
    "        return [self.g_w1, self.g_b1, self.g_w2, self.g_b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# next, we need a function to actually generate a 100d noise vector to feed into our generator\n",
    "def rand_noise_vector(num_vectors, size):\n",
    "    return np.random.uniform(-1.0, 1.0, size = [num_vectors, size]) # we might want a bunch of these to generate many imgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# a function to plot the genned images\n",
    "def plot(samples, cur_epoch = None):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "        # if epoch is not specified we just overwrite the existing image\n",
    "        plt.savefig(\"gan{}\".format(\"\" if cur_epoch is None else cur_epoch))\n",
    "        plt.show()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create networks\n",
    "gen_net, discriminator_net = generator_network(), discriminator_network()\n",
    "# compute G(z) where z is the random noise vector \n",
    "g_sample = gen_net.generator(z=Z)\n",
    "# compute d(real) = p(image being real)\n",
    "d_prob_real, d_logit_real = discriminator_net.discriminator(X)\n",
    "# compute d(fake) = p(image being real)\n",
    "d_prob_fake, d_logit_fake = discriminator_net.discriminator(g_sample)\n",
    "\n",
    "# optimize wrspt to the real logits, so all tha labels are one since we knew they came from real samples\n",
    "d_real_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logit_real, labels = tf.ones_like(d_logit_real)))\n",
    "# optimize wrspt to the fake logits, so all the labels are zero since we knew that they came from fake (generated) samples\n",
    "d_fake_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = d_logit_fake, labels = tf.zeros_like(d_logit_fake)))\n",
    "# total loss is just the sum\n",
    "d_loss = d_real_loss + d_fake_loss\n",
    "\n",
    "# train the generator w/fake logits\n",
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = d_logit_fake, labels = tf.ones_like(d_logit_fake)))\n",
    "\n",
    "# make sure to only train w/relevant vars\n",
    "d_step = tf.train.AdamOptimizer().minimize(d_loss, var_list = discriminator_net.get_trainable_vars())\n",
    "g_step = tf.train.AdamOptimizer().minimize(g_loss, var_list = gen_net.get_trainable_vars())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    i = 0\n",
    "    for epoch in range(100000): # increase this for more accuracy, but it will be more likely to collapse\n",
    "        X_mb, _ = mnist.train.next_batch(128)\n",
    "        _, cur_loss_d = sess.run([d_step, d_loss], feed_dict = {X: X_mb, Z: rand_noise_vector(128, 100)})\n",
    "        _, cur_loss_g = sess.run([g_step, g_loss], feed_dict = {Z: rand_noise_vector(128, 100)})\n",
    "        _, cur_loss_g = sess.run([g_step, g_loss], feed_dict = {Z: rand_noise_vector(128, 100)})\n",
    "        if epoch % 1000 == 0:\n",
    "            print(\"Epoch: {}\".format(epoch))\n",
    "            print(\"Discriminator loss: {}\".format(cur_loss_d))\n",
    "            print(\"Generator loss: {}\".format(cur_loss_g))\n",
    "            samples = sess.run(g_sample, feed_dict={Z: rand_noise_vector(1, 100)})\n",
    "            plot(samples, epoch)\n",
    "    samples = sess.run(g_sample, feed_dict={Z: rand_noise_vector(16, 100)})\n",
    "    plot(samples) # 16 of em\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
